"""This module contains all configuration information used to run simulations
"""
from multiprocessing import cpu_count
from collections import deque
import copy
from icarus.util import Tree

# GENERAL SETTINGS

# Level of logging output
# Available options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL = 'INFO'

# If True, executes simulations in parallel using multiple processes
# to take advantage of multicore CPUs
PARALLEL_EXECUTION = True

# Number of processes used to run simulations in parallel.
# This option is ignored if PARALLEL_EXECUTION = False
N_PROCESSES = cpu_count()

# Granularity of caching.
# Currently, only OBJECT is supported
CACHING_GRANULARITY = 'OBJECT'

# Format in which results are saved.
# Result readers and writers are located in module ./icarus/results/readwrite.py
# Currently only PICKLE is supported 
RESULTS_FORMAT = 'PICKLE'

# Number of times each experiment is replicated
# This is necessary for extracting confidence interval of selected metrics
N_REPLICATIONS = 30

# List of metrics to be measured in the experiments
# The implementation of data collectors are located in ./icaurs/execution/collectors.py
DATA_COLLECTORS = ['CACHE_HIT_RATIO', 'LATENCY']

# Range of alpha values of the Zipf distribution using to generate content requests
# alpha values must be positive. The greater the value the more skewed is the 
# content popularity distribution
# Range of alpha values of the Zipf distribution using to generate content requests
# alpha values must be positive. The greater the value the more skewed is the 
# content popularity distribution
# Note: to generate these alpha values, numpy.arange could also be used, but it
# is not recommended because generated numbers may be not those desired. 
# E.g. arange may return 0.799999999999 instead of 0.8. 
# This would give problems while trying to plot the results because if for
# example I wanted to filter experiment with alpha=0.8, experiments with
# alpha = 0.799999999999 would not be recognized 
ALPHA = [1.0]

# Total size of network cache as a fraction of content population
#80 percent contents can be cached intra group

NETWORK_CACHE = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]
# Number of content objects
#N_CONTENTS = 3*10**4
N_CONTENTS = 32*10**4
# Number of requests per second (over the whole network)
NETWORK_REQUEST_RATE = 300.0

# Number of content requests generated to prepopulate the caches
# These requests are not logged
#N_WARMUP_REQUESTS = 6*10**4
N_WARMUP_REQUESTS = 64*10**4
# Number of content requests generated after the warmup and logged
# to generate results. 
#N_MEASURED_REQUESTS = 6*10**5
N_MEASURED_REQUESTS = 64*10**4
# Number of workload ranks over all nodes 
N_RANKS = [
        4,    
        32
        ]


#generate topology
#nodes of group leader are generated by needed, not included in N_NODE
#N_CORE,N_NODE=map(int,raw_input("generating 3 layer datacenter network,\n \
        #input number of central data store, caching nodes seperated by commas:\n").split(','))
#N_SIZE=raw_input(" input list of group size, seperated by commas\n \
        #make sure number of nodes can be devided by group size:\n").split(',')
#N_SIZES= [int(x.strip()) for x in N_SIZE]

N_CORE = 1
N_NODE = 320
#group_num = N_NODE/N_SIZES : 32, 1
N_SIZES = [10, 320] 

TOPOLOGIES = [
                'EDGEFOG'
                ]
# List of caching and routing strategies
# The code is located in ./icarus/models/strategy/offpath.py
STRATEGIES = [
                'NRR' #Ideal Nearest Replica Routing (NRR) strategy     
            ]

GROUPS = [
            'GROUP',
            'NOTGROUP'
            ]

"""RANK_GROUPS = [
            '4GROUP',
            '4NOTGROUP',
            '32GROUP',
            '32NOTGROUP'
            ]"""
RANK_GROUPS = ["" for x in range(len(N_RANKS)*len(GROUPS))]
index = 0
for i in N_RANKS:
    for j in GROUPS:
        RANK_GROUPS[index] = str(i) + ',' + j
        index += 1
# Cache replacement policy used by the network caches.
# Supported policies are: 'LRU', 'LFU', 'FIFO', 'RAND' and 'NULL'
# Cache policy implmentations are located in ./icarus/models/cache.py
CACHE_POLICY = 'LRU'

# Queue of experiments
EXPERIMENT_QUEUE = deque()
default = Tree()
default['workload'] = {'name':       'DIFFRANK',
                       #'n_rank':     N_RANK,
                       #'n_contents': N_CONTENTS,
                       'n_warmup':   N_WARMUP_REQUESTS,
                       'n_measured': N_MEASURED_REQUESTS,
                       'rate':       NETWORK_REQUEST_RATE
                       }
default['topology'] = { 
                        'n_datastore':N_CORE  
                        }
default['cache_placement']['name'] = 'UNIFORM'
default['content_placement']['name'] = 'UNIFORM'
default['cache_policy']['name'] = CACHE_POLICY
# Create experiments multiplexing all desired parameters
for alpha in ALPHA:
    for strategy in STRATEGIES:
        for topology in TOPOLOGIES:
            for network_cache in NETWORK_CACHE:
                for rankgroup in RANK_GROUPS:
                    experiment = copy.deepcopy(default)
                    experiment['rankgroup']['name'] = rankgroup
                    experiment['group']['name'] = rankgroup.split(',')[1]
                    experiment['workload']['n_rank'] = int(rankgroup.split(',')[0])
                    experiment['workload']['alpha'] = alpha
                    #overall number of workloads remain same, workloads intra group changes according to size
                    if experiment['group']['name'] == 'GROUP':
                        experiment['topology']['n_member'] = int(N_NODE/experiment['workload']['n_rank'])
                        experiment['workload']['rank_per_group'] = int(1)
                    else:
                        experiment['topology']['n_member'] = int(N_NODE) 
                        experiment['workload']['rank_per_group'] = int(experiment['workload']['n_rank'])
                    experiment['workload']['n_contents'] = N_CONTENTS/int(experiment['workload']['n_rank'])
		    experiment['strategy']['name'] = strategy
                    experiment['topology']['name'] = topology
                    experiment['topology']['n_node'] = N_NODE
                    experiment['cache_placement']['network_cache'] = network_cache
                    experiment['desc'] = "Alpha: %s, strategy: %s,  network cache: %s, topology: Edgefog, num of datastore: %s, rank&group: %s. " % (str(alpha), strategy, str(network_cache), str(N_CORE),rankgroup )
                    EXPERIMENT_QUEUE.append(experiment)
